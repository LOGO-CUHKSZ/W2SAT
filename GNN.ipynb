{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(node_features, 64)\n",
    "        self.conv2 = GCNConv(64, 32)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils \n",
    "\n",
    "def read_sat(sat_path):\n",
    "    with open(sat_path) as f:\n",
    "        sat_lines = f.readlines()\n",
    "        header = sat_lines[0]\n",
    "        header_info = header.replace(\"\\n\", \"\").split(\" \")\n",
    "        num_vars = int(header_info[-2])\n",
    "        num_clauses = int(header_info[-1])\n",
    "\n",
    "        sat = [[int(x) for x in line.replace(' 0\\n', '').split(' ')]\n",
    "               for line in sat_lines[1:]]\n",
    "\n",
    "        return sat, num_vars, num_clauses\n",
    "\n",
    "\n",
    "def sat_to_lig_adjacency_matrix(sat, num_vars):\n",
    "    get_literal_idx = lambda x: 2 * x - 2 if x > 0 else 2 * abs(x) - 1\n",
    "    lig_adjacency_matrix = np.zeros([2*num_vars, 2*num_vars])\n",
    "    lig_weighted_adjacency_matrix = np.zeros([2*num_vars, 2*num_vars])\n",
    "\n",
    "    for clause in sat:\n",
    "        pairs = it.combinations(clause, 2)\n",
    "#         print(f'clause: {clause}')\n",
    "        for pair in pairs:\n",
    "            x_idx = get_literal_idx(pair[0])\n",
    "            y_idx = get_literal_idx(pair[1])\n",
    "#             print(f'pair: {(x_idx, y_idx)}')\n",
    "            lig_adjacency_matrix[x_idx, y_idx] = 1\n",
    "            lig_adjacency_matrix[y_idx, x_idx] = 1\n",
    "            lig_weighted_adjacency_matrix[x_idx, y_idx] += 1\n",
    "            lig_weighted_adjacency_matrix[y_idx, x_idx] += 1    \n",
    "    return lig_adjacency_matrix, lig_weighted_adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 1. ... 2. 1. 3.]\n",
      "[1.         1.         0.16666667 ... 0.33333333 0.16666667 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "sat_path = './ssa2670-141.processed.cnf'\n",
    "sat_instance, num_vars, num_clauses = read_sat(sat_path)\n",
    "\n",
    "lig_adjacency_matrix, lig_weighted_adjacency_matrix = sat_to_lig_adjacency_matrix(sat_instance, num_vars)\n",
    "\n",
    "# graph = nx.from_numpy_matrix(lig_adjacency_matrix)\n",
    "# edges = nx.to_edgelist(graph)\n",
    "# print(lig_adjacency_matrix.nonzero())\n",
    "\n",
    "edge_index = torch.tensor(lig_adjacency_matrix.nonzero(), dtype=torch.long)\n",
    "edge_value = lig_weighted_adjacency_matrix[lig_adjacency_matrix.nonzero()]\n",
    "print(edge_value)\n",
    "max_edge_value = max(edge_value)\n",
    "norm_edge_value = edge_value/max_edge_value\n",
    "print(norm_edge_value)\n",
    "embeddings = torch.load('./embeddings.pt')\n",
    "embeddings.requires_grad = False\n",
    "# print(embeddings)\n",
    "x = embeddings\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, norm_edge_value=norm_edge_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.3352663815021515\n",
      "epoch: 1, loss: 0.16129252314567566\n",
      "epoch: 2, loss: 0.11396269500255585\n",
      "epoch: 3, loss: 0.11215722560882568\n",
      "epoch: 4, loss: 0.11726173013448715\n",
      "epoch: 5, loss: 0.118002749979496\n",
      "epoch: 6, loss: 0.11455845087766647\n",
      "epoch: 7, loss: 0.10962137579917908\n",
      "epoch: 8, loss: 0.10485920310020447\n",
      "epoch: 9, loss: 0.10081926733255386\n",
      "epoch: 10, loss: 0.09754770994186401\n",
      "epoch: 11, loss: 0.09503047913312912\n",
      "epoch: 12, loss: 0.09319749474525452\n",
      "epoch: 13, loss: 0.09193914383649826\n",
      "epoch: 14, loss: 0.09112832695245743\n",
      "epoch: 15, loss: 0.09065461158752441\n",
      "epoch: 16, loss: 0.09039942920207977\n",
      "epoch: 17, loss: 0.09026653319597244\n",
      "epoch: 18, loss: 0.09018757194280624\n",
      "epoch: 19, loss: 0.09012112766504288\n",
      "epoch: 20, loss: 0.09004461020231247\n",
      "epoch: 21, loss: 0.08994879573583603\n",
      "epoch: 22, loss: 0.08982842415571213\n",
      "epoch: 23, loss: 0.08969057351350784\n",
      "epoch: 24, loss: 0.08954218775033951\n",
      "epoch: 25, loss: 0.08939193189144135\n",
      "epoch: 26, loss: 0.0892476886510849\n",
      "epoch: 27, loss: 0.0891159325838089\n",
      "epoch: 28, loss: 0.08900071680545807\n",
      "epoch: 29, loss: 0.08890222012996674\n",
      "epoch: 30, loss: 0.08881930261850357\n",
      "epoch: 31, loss: 0.0887511596083641\n",
      "epoch: 32, loss: 0.08869510889053345\n",
      "epoch: 33, loss: 0.08864731341600418\n",
      "epoch: 34, loss: 0.08860592544078827\n",
      "epoch: 35, loss: 0.0885700210928917\n",
      "epoch: 36, loss: 0.08853822201490402\n",
      "epoch: 37, loss: 0.08850927650928497\n",
      "epoch: 38, loss: 0.08848308771848679\n",
      "epoch: 39, loss: 0.08846008777618408\n",
      "epoch: 40, loss: 0.08844070881605148\n",
      "epoch: 41, loss: 0.0884246826171875\n",
      "epoch: 42, loss: 0.08841194212436676\n",
      "epoch: 43, loss: 0.08840199559926987\n",
      "epoch: 44, loss: 0.08839412033557892\n",
      "epoch: 45, loss: 0.088387630879879\n",
      "epoch: 46, loss: 0.08838190883398056\n",
      "epoch: 47, loss: 0.08837658911943436\n",
      "epoch: 48, loss: 0.08837127685546875\n",
      "epoch: 49, loss: 0.08836578577756882\n",
      "epoch: 50, loss: 0.0883600264787674\n",
      "epoch: 51, loss: 0.08835384994745255\n",
      "epoch: 52, loss: 0.08834725618362427\n",
      "epoch: 53, loss: 0.08834023028612137\n",
      "epoch: 54, loss: 0.08833286166191101\n",
      "epoch: 55, loss: 0.08832534402608871\n",
      "epoch: 56, loss: 0.08831792324781418\n",
      "epoch: 57, loss: 0.0883108377456665\n",
      "epoch: 58, loss: 0.0883043184876442\n",
      "epoch: 59, loss: 0.08829857409000397\n",
      "epoch: 60, loss: 0.08829373866319656\n",
      "epoch: 61, loss: 0.08828979730606079\n",
      "epoch: 62, loss: 0.08828674256801605\n",
      "epoch: 63, loss: 0.08828449249267578\n",
      "epoch: 64, loss: 0.08828281611204147\n",
      "epoch: 65, loss: 0.08828151226043701\n",
      "epoch: 66, loss: 0.08828037977218628\n",
      "epoch: 67, loss: 0.08827926963567734\n",
      "epoch: 68, loss: 0.08827807754278183\n",
      "epoch: 69, loss: 0.08827672898769379\n",
      "epoch: 70, loss: 0.0882752314209938\n",
      "epoch: 71, loss: 0.08827361464500427\n",
      "epoch: 72, loss: 0.08827188611030579\n",
      "epoch: 73, loss: 0.08827012032270432\n",
      "epoch: 74, loss: 0.08826837688684464\n",
      "epoch: 75, loss: 0.08826667815446854\n",
      "epoch: 76, loss: 0.08826509118080139\n",
      "epoch: 77, loss: 0.0882636085152626\n",
      "epoch: 78, loss: 0.08826226741075516\n",
      "epoch: 79, loss: 0.08826107531785965\n",
      "epoch: 80, loss: 0.0882599800825119\n",
      "epoch: 81, loss: 0.0882590040564537\n",
      "epoch: 82, loss: 0.08825812488794327\n",
      "epoch: 83, loss: 0.08825729787349701\n",
      "epoch: 84, loss: 0.08825651556253433\n",
      "epoch: 85, loss: 0.08825576305389404\n",
      "epoch: 86, loss: 0.08825504034757614\n",
      "epoch: 87, loss: 0.08825433254241943\n",
      "epoch: 88, loss: 0.08825365453958511\n",
      "epoch: 89, loss: 0.0882529765367508\n",
      "epoch: 90, loss: 0.08825232088565826\n",
      "epoch: 91, loss: 0.08825167268514633\n",
      "epoch: 92, loss: 0.0882510244846344\n",
      "epoch: 93, loss: 0.08825039863586426\n",
      "epoch: 94, loss: 0.08824978023767471\n",
      "epoch: 95, loss: 0.08824919164180756\n",
      "epoch: 96, loss: 0.0882486030459404\n",
      "epoch: 97, loss: 0.08824802935123444\n",
      "epoch: 98, loss: 0.08824746310710907\n",
      "epoch: 99, loss: 0.0882469117641449\n",
      "epoch: 100, loss: 0.08824636787176132\n",
      "epoch: 101, loss: 0.08824585378170013\n",
      "epoch: 102, loss: 0.08824533969163895\n",
      "epoch: 103, loss: 0.08824487030506134\n",
      "epoch: 104, loss: 0.08824440836906433\n",
      "epoch: 105, loss: 0.08824395388364792\n",
      "epoch: 106, loss: 0.0882434993982315\n",
      "epoch: 107, loss: 0.08824308216571808\n",
      "epoch: 108, loss: 0.08824266493320465\n",
      "epoch: 109, loss: 0.08824225515127182\n",
      "epoch: 110, loss: 0.0882418304681778\n",
      "epoch: 111, loss: 0.08824143558740616\n",
      "epoch: 112, loss: 0.08824104815721512\n",
      "epoch: 113, loss: 0.08824065327644348\n",
      "epoch: 114, loss: 0.08824026584625244\n",
      "epoch: 115, loss: 0.0882398784160614\n",
      "epoch: 116, loss: 0.08823952823877335\n",
      "epoch: 117, loss: 0.0882391706109047\n",
      "epoch: 118, loss: 0.08823882788419724\n",
      "epoch: 119, loss: 0.08823850005865097\n",
      "epoch: 120, loss: 0.0882381796836853\n",
      "epoch: 121, loss: 0.08823785930871964\n",
      "epoch: 122, loss: 0.08823755383491516\n",
      "epoch: 123, loss: 0.08823726326227188\n",
      "epoch: 124, loss: 0.0882369801402092\n",
      "epoch: 125, loss: 0.08823669701814651\n",
      "epoch: 126, loss: 0.08823642134666443\n",
      "epoch: 127, loss: 0.08823615312576294\n",
      "epoch: 128, loss: 0.08823587745428085\n",
      "epoch: 129, loss: 0.08823563158512115\n",
      "epoch: 130, loss: 0.08823538571596146\n",
      "epoch: 131, loss: 0.08823513239622116\n",
      "epoch: 132, loss: 0.08823489397764206\n",
      "epoch: 133, loss: 0.08823466300964355\n",
      "epoch: 134, loss: 0.08823443949222565\n",
      "epoch: 135, loss: 0.08823420107364655\n",
      "epoch: 136, loss: 0.08823397755622864\n",
      "epoch: 137, loss: 0.08823376893997192\n",
      "epoch: 138, loss: 0.08823355287313461\n",
      "epoch: 139, loss: 0.0882333442568779\n",
      "epoch: 140, loss: 0.08823314309120178\n",
      "epoch: 141, loss: 0.08823293447494507\n",
      "epoch: 142, loss: 0.08823274821043015\n",
      "epoch: 143, loss: 0.08823256194591522\n",
      "epoch: 144, loss: 0.0882323756814003\n",
      "epoch: 145, loss: 0.08823219686746597\n",
      "epoch: 146, loss: 0.08823201060295105\n",
      "epoch: 147, loss: 0.08823183923959732\n",
      "epoch: 148, loss: 0.08823167532682419\n",
      "epoch: 149, loss: 0.08823151141405106\n",
      "epoch: 150, loss: 0.08823134750127792\n",
      "epoch: 151, loss: 0.08823119103908539\n",
      "epoch: 152, loss: 0.08823103457689285\n",
      "epoch: 153, loss: 0.08823087811470032\n",
      "epoch: 154, loss: 0.08823072910308838\n",
      "epoch: 155, loss: 0.08823058754205704\n",
      "epoch: 156, loss: 0.0882304459810257\n",
      "epoch: 157, loss: 0.08823031932115555\n",
      "epoch: 158, loss: 0.0882301852107048\n",
      "epoch: 159, loss: 0.08823005110025406\n",
      "epoch: 160, loss: 0.08822992444038391\n",
      "epoch: 161, loss: 0.08822978287935257\n",
      "epoch: 162, loss: 0.08822966367006302\n",
      "epoch: 163, loss: 0.08822955191135406\n",
      "epoch: 164, loss: 0.08822943270206451\n",
      "epoch: 165, loss: 0.08822931349277496\n",
      "epoch: 166, loss: 0.0882292091846466\n",
      "epoch: 167, loss: 0.08822908997535706\n",
      "epoch: 168, loss: 0.0882289856672287\n",
      "epoch: 169, loss: 0.08822887390851974\n",
      "epoch: 170, loss: 0.08822877705097198\n",
      "epoch: 171, loss: 0.08822866529226303\n",
      "epoch: 172, loss: 0.08822856843471527\n",
      "epoch: 173, loss: 0.08822847157716751\n",
      "epoch: 174, loss: 0.08822838217020035\n",
      "epoch: 175, loss: 0.08822828531265259\n",
      "epoch: 176, loss: 0.08822820335626602\n",
      "epoch: 177, loss: 0.08822811394929886\n",
      "epoch: 178, loss: 0.0882280245423317\n",
      "epoch: 179, loss: 0.08822794258594513\n",
      "epoch: 180, loss: 0.08822785317897797\n",
      "epoch: 181, loss: 0.088227778673172\n",
      "epoch: 182, loss: 0.08822768181562424\n",
      "epoch: 183, loss: 0.08822761476039886\n",
      "epoch: 184, loss: 0.0882275253534317\n",
      "epoch: 185, loss: 0.08822745829820633\n",
      "epoch: 186, loss: 0.08822739124298096\n",
      "epoch: 187, loss: 0.08822732418775558\n",
      "epoch: 188, loss: 0.08822723478078842\n",
      "epoch: 189, loss: 0.08822718262672424\n",
      "epoch: 190, loss: 0.08822710812091827\n",
      "epoch: 191, loss: 0.0882270410656929\n",
      "epoch: 192, loss: 0.08822698146104813\n",
      "epoch: 193, loss: 0.08822691440582275\n",
      "epoch: 194, loss: 0.08822685480117798\n",
      "epoch: 195, loss: 0.0882268026471138\n",
      "epoch: 196, loss: 0.08822674304246902\n",
      "epoch: 197, loss: 0.08822668343782425\n",
      "epoch: 198, loss: 0.08822663128376007\n",
      "epoch: 199, loss: 0.08822658658027649\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = GCN(50)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# print(norm_edge_value)\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    src, dst = edge_index\n",
    "    score = (out[src] * out[dst]).sum(dim=-1)\n",
    "    score = torch.sigmoid(score)\n",
    "    loss = F.mse_loss(score, torch.tensor(norm_edge_value, dtype=torch.float))\n",
    "    print(f'epoch: {epoch}, loss: {loss.item()}')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7df9adec5398d45472c8bf81047aa2ae699f575f599903d765e95bf4a199fe03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
